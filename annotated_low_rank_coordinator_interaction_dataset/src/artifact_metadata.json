{
  "title": "Multi-LLM Agent Coordination Dataset with Token-Level Communication Logs",
  "summary": "This dataset contains 200 curated multi-LLM agent interaction episodes from lmsys/chatbot_arena_conversations, enriched with comprehensive token-level communication metadata. Each example features two LLM agents (model_a and model_b) coordinating on the same task, with detailed per-turn token counts, communication efficiency metrics, and human-judged winner labels. The dataset addresses hypothesis requirement (a) token-level communication logs with complete per-turn tracking (input_tokens, response_a_tokens, response_b_tokens), message lengths, and efficiency metrics (avg_tokens_per_turn, input_output_ratio, coordination_overhead). Dataset statistics: 132,652 total tokens, 663.3 average tokens per example, 42 unique model pairs, balanced winner distribution (39.5% model_a, 38.5% model_b, 22.0% tie). Four output files generated: data_out.json (200 examples, 759KB), full_data_out.json (compatibility copy), mini_data_out.json (3 examples for testing), preview_data_out.json (3 truncated examples for inspection). Schema-validated against exp_sel_data_out.json. Ready for annotation pipeline to add (b) low-rank recurrent coordinator latent states and (c) explicit coordination outcome labels. Downstream artifacts can use this dataset to train and benchmark low-rank coordinator architectures for improved token efficiency in multi-agent systems."
}
