{
 "cells": [
  {
   "cell_type": "code",
   "source": "# Examine a complete example\nprint(\"\\\\n\" + \"=\" * 60)\nprint(\"üîç Detailed Example Structure\")\nprint(\"=\" * 60)\n\nexample = standardized_examples[0]\nprint(f\"\\\\nüìù Input Query: {example['input']}\")\nprint(f\"\\\\nüèÜ Coordination Outcome: {example['output']}\")\nprint(f\"\\\\nüè∑Ô∏è  Dataset: {example['dataset']}\")\nprint(f\"\\\\nüìä Split: {example['split']}\")\n\nprint(\"\\\\nü§ñ Model Context:\")\ncontext = example['context']\nprint(f\"  Model A: {context['model_a']}\")\nprint(f\"  Model B: {context['model_b']}\")\nprint(f\"  Winner: {context['winner']}\")\nprint(f\"  Judge: {context['judge']}\")\nprint(f\"  Language: {context['language']}\")\nprint(f\"  Turn: {context['turn']}\")\n\nprint(\"\\\\nüí¨ Response Excerpts:\")\nprint(f\"  Model A ({context['model_a']}):\")\nprint(f\"    '{context['response_a'][:100]}...'\")\nprint(f\"  Model B ({context['model_b']}):\")\nprint(f\"    '{context['response_b'][:100]}...'\")\n\nprint(\"\\\\nüìà Token Usage Details:\")\ntoken_usage = context['token_usage']\nprint(f\"  Total tokens: {token_usage['total_tokens']}\")\nprint(f\"  Input tokens: {token_usage['total_input_tokens']}\")\nprint(f\"  Output A tokens: {token_usage['total_output_tokens_a']}\")\nprint(f\"  Output B tokens: {token_usage['total_output_tokens_b']}\")\n\nprint(\"\\\\n‚öôÔ∏è API Metadata:\")\napi_meta = context['api_metadata']\nprint(f\"  Question ID: {api_meta.get('question_id', 'N/A')}\")\nprint(f\"  Timestamp: {api_meta.get('timestamp', 'N/A')}\")\nprint(f\"  Anonymous: {api_meta.get('anony', 'N/A')}\")\nif 'toxic_chat_tag' in api_meta:\n    print(f\"  Toxic content flags: {list(api_meta['toxic_chat_tag'].keys())}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Example Data Exploration\n\nLet's examine one complete example to understand the data structure:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Communication Efficiency Analysis\nprint(\"\\\\n\" + \"=\" * 60)\nprint(\"üìä Communication Efficiency Metrics\")\nprint(\"=\" * 60)\n\nefficiency_metrics = []\nfor i, ex in enumerate(standardized_examples):\n    comm_eff = ex[\"context\"][\"token_usage\"][\"communication_efficiency\"]\n    efficiency_metrics.append(comm_eff)\n    \n    print(f\"\\\\nExample {i+1}: {ex['input'][:40]}...\")\n    print(f\"  Average tokens per turn: {comm_eff['avg_tokens_per_turn']:.1f}\")\n    print(f\"  Input/Output ratio: {comm_eff['input_output_ratio']:.3f}\")\n    print(f\"  Coordination overhead: {comm_eff['coordination_overhead']:.3f}\")\n    print(f\"  Winner: {ex['context']['winner']}\")\n\n# Overall averages\navg_tokens_per_turn = sum(m['avg_tokens_per_turn'] for m in efficiency_metrics) / len(efficiency_metrics)\navg_io_ratio = sum(m['input_output_ratio'] for m in efficiency_metrics) / len(efficiency_metrics)\navg_coord_overhead = sum(m['coordination_overhead'] for m in efficiency_metrics) / len(efficiency_metrics)\n\nprint(f\"\\\\nüìà Overall Averages:\")\nprint(f\"  Average tokens per turn: {avg_tokens_per_turn:.1f}\")\nprint(f\"  Average input/output ratio: {avg_io_ratio:.3f}\")\nprint(f\"  Average coordination overhead: {avg_coord_overhead:.3f}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Communication Efficiency Analysis\n\nLet's dive deeper into the communication efficiency metrics that are crucial for coordinator analysis:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Dataset Statistics\nprint(\"=\" * 60)\nprint(\"üìà Dataset Statistics\")\nprint(\"=\" * 60)\nprint(f\"Total examples: {len(standardized_examples)}\")\nprint(f\"Dataset source: lmsys/chatbot_arena_conversations\")\nprint(f\"Split: train\")\n\n# Token statistics\ntotal_tokens = sum(\n    ex[\"context\"][\"token_usage\"][\"total_tokens\"]\n    for ex in standardized_examples\n)\navg_tokens = total_tokens / len(standardized_examples) if standardized_examples else 0\nprint(f\"\\\\nToken Usage:\")\nprint(f\"  Total tokens: {total_tokens:,}\")\nprint(f\"  Average tokens per example: {avg_tokens:.1f}\")\n\n# Winner distribution\nwinner_counts = {}\nfor ex in standardized_examples:\n    winner = ex[\"context\"][\"winner\"]\n    winner_counts[winner] = winner_counts.get(winner, 0) + 1\n\nprint(f\"\\\\nWinner Distribution:\")\nfor winner, count in sorted(winner_counts.items()):\n    pct = (count / len(standardized_examples)) * 100\n    print(f\"  {winner}: {count} ({pct:.1f}%)\")\n\n# Model coverage\nmodel_pairs = set()\nfor ex in standardized_examples:\n    pair = (ex[\"context\"][\"model_a\"], ex[\"context\"][\"model_b\"])\n    model_pairs.add(pair)\n\nprint(f\"\\\\nModel Pairs: {len(model_pairs)} unique combinations\")\nfor pair in sorted(model_pairs):\n    print(f\"  {pair[0]} vs {pair[1]}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Dataset Analysis\n\nLet's examine our processed dataset and generate key statistics about model coordination patterns:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Process examples through standardization\nexamples = sample_data.get(\"examples\", [])\nprint(f\"üìä Processing {len(examples)} examples from source dataset\")\n\nstandardized_examples = []\n\nfor i, example in enumerate(examples):\n    try:\n        std_example = standardize_example(\n            example,\n            dataset_name=\"lmsys/chatbot_arena_conversations\"\n        )\n        standardized_examples.append(std_example)\n        print(f\"‚úÖ Successfully processed example {i+1}: '{std_example['input'][:50]}...'\")\n    except Exception as e:\n        print(f\"‚ö†Ô∏è  Warning: Failed to process example {i}: {e}\")\n        continue\n\nprint(f\"\\\\n‚úÖ Successfully standardized {len(standardized_examples)} examples\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Process the Dataset\n\nLet's apply the standardization function to our sample data and explore the results:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "def standardize_example(example: Dict[str, Any], dataset_name: str) -> Dict[str, Any]:\n    \"\"\"\n    Convert ChatBot Arena example to standardized schema format.\n    \n    Required fields: input, context, output, dataset, split\n    \"\"\"\n    # Extract input (user query)\n    input_text = example.get(\"input\", \"\")\n    \n    # Build context with all coordination-relevant metadata\n    context = {\n        \"model_a\": example[\"context\"][\"model_a\"],\n        \"model_b\": example[\"context\"][\"model_b\"],\n        \"winner\": example[\"context\"][\"winner\"],\n        \"judge\": example[\"context\"].get(\"judge\", \"unknown\"),\n        \"language\": example[\"context\"].get(\"language\", \"unknown\"),\n        \"turn\": example[\"context\"].get(\"turn\", 1),\n        \"response_a\": example[\"context\"][\"response_a\"],\n        \"response_b\": example[\"context\"][\"response_b\"],\n        \"token_usage\": example[\"context\"][\"token_usage\"],\n        \"api_metadata\": example[\"context\"].get(\"api_metadata\", {}),\n    }\n    \n    # Extract output (coordination outcome - winner label)\n    output = example.get(\"output\", \"\")\n    \n    # Get split\n    split = example.get(\"split\", \"train\")\n    \n    return {\n        \"input\": input_text,\n        \"context\": context,\n        \"output\": output,\n        \"dataset\": dataset_name,\n        \"split\": split\n    }\n\nprint(\"‚úÖ Data standardization function defined!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Data Standardization Function\n\nThe core function that converts raw ChatBot Arena data to the standardized schema format required for downstream ML research:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Sample dataset - inlined for self-contained notebook\nsample_data = {\n    \"examples\": [\n        {\n            \"input\": \"What is the difference between OpenCL and CUDA?\",\n            \"context\": {\n                \"model_a\": \"chatglm-6b\",\n                \"model_b\": \"koala-13b\", \n                \"winner\": \"model_b\",\n                \"judge\": \"arena_user_973\",\n                \"language\": \"English\",\n                \"turn\": 1,\n                \"response_a\": \"OpenCL and CUDA are two different programming models that are used for parallel computing.OpenCL is a general-purposeÂπ∂Ë°åÁºñÁ®ãÊé•Âè£ that allows developers to write parallel code that can run on any platform that supportsCL, which includes most modern operating systems and computer systems, including Windows, Linux, and macOS. It provides a lower-level, more flexible API that is more suitable for building large-scale distributed computing systems.CUDA is a specific implementation ofOpenCL that is designed for performance and scalability in devices with multiple GPU(s). It was developed by Nvidia and is widely used for scientific computing, machine learning, andÂõæÂΩ¢ÂõæÂÉèÂ§ÑÁêÜ. The CUDA API provides a high-level, more efficient way to write parallel code that can run on top of a GPU, while still maintaining the ability to write code that can be easily adapted for other parallel computing platforms.\",\n                \"response_b\": \"OpenCL and CUDA are both programming languages for parallel computing on GPUs, but they differ in several key ways:\\\\n\\\\n1.   Architecture: OpenCL is a general-purpose parallel computing language, while CUDA is designed specifically for GPU computing. OpenCL can run on various types of processors, including CPUs, GPUs, and FPGAs, whereas CUDA is only compatible with NVIDIA GPUs.\\\\n2.   Language: OpenCL is a C++ language, while CUDA is a C++ language with additional features for GPU computing. CUDA provides additional libraries and tools for handling graphics and other tasks unique to GPUs.\\\\n3.   Driver support: OpenCL has a wider range of device support, with support for not just NVIDIA GPUs but also other manufacturers like AMD, Intel, and ARM. CUDA is only available on NVIDIA GPUs, and requires the CUDA Toolkit to be installed on the host machine.\\\\n4.   Memory management: OpenCL provides a unified memory model, where all the data is stored in global memory, and the kernel can access any part of it. CUDA, on the other hand, uses a hierarchical memory architecture, where data is divided into host, device, and shared memory.\\\\n5.   Performance: OpenCL and CUDA have different strengths and weaknesses in terms of performance. OpenCL is generally faster for numerical computations, while CUDA is faster for graphics and other tasks that require fast memory access. CUDA also has better support for 64-bit floating-point operations, which are essential for some scientific applications.\\\\n\\\\nIn summary, OpenCL and CUDA are both programming languages for parallel computing on GPUs, but they differ in terms of architecture, language, driver support, memory management, and performance. OpenCL is a general-purpose language that can run on various types of processors, while CUDA is specific to NVIDIA GPUs and provides additional libraries and tools for handling graphics and other tasks unique to GPUs.\",\n                \"token_usage\": {\n                    \"turns\": [\n                        {\n                            \"turn_number\": 1,\n                            \"timestamp_offset\": 0.0,\n                            \"input_tokens\": 10,\n                            \"input_length\": 47,\n                            \"response_a_tokens\": 171,\n                            \"response_a_length\": 892,\n                            \"response_b_tokens\": 373,\n                            \"response_b_length\": 1905\n                        },\n                        {\n                            \"turn_number\": 2,\n                            \"timestamp_offset\": 5.0,\n                            \"input_tokens\": 171,\n                            \"input_length\": 892\n                        }\n                    ],\n                    \"total_input_tokens\": 181,\n                    \"total_output_tokens_a\": 171,\n                    \"total_output_tokens_b\": 373,\n                    \"total_tokens\": 725,\n                    \"message_lengths\": {\n                        \"input\": [47, 892],\n                        \"response_a\": [892],\n                        \"response_b\": [1905]\n                    },\n                    \"communication_efficiency\": {\n                        \"avg_tokens_per_turn\": 362.5,\n                        \"input_output_ratio\": 0.2496551724137931,\n                        \"coordination_overhead\": 0.2786206896551724\n                    }\n                },\n                \"api_metadata\": {\n                    \"question_id\": \"58210e39b3fd4441a2bd4a518bb44c2d\",\n                    \"timestamp\": 1682351591.1322,\n                    \"toxic_chat_tag\": {\n                        \"roberta-large\": {\"flagged\": False, \"probability\": 0.0083130226},\n                        \"t5-large\": {\"flagged\": False, \"score\": 7.94367e-05}\n                    },\n                    \"anony\": True\n                }\n            },\n            \"output\": \"Winner: model_b\",\n            \"dataset\": \"lmsys/chatbot_arena_conversations\",\n            \"split\": \"train\"\n        },\n        {\n            \"input\": \"Why did my parent not invite me to their wedding?\",\n            \"context\": {\n                \"model_a\": \"oasst-pythia-12b\",\n                \"model_b\": \"alpaca-13b\",\n                \"winner\": \"tie\",\n                \"judge\": \"arena_user_973\",\n                \"language\": \"English\",\n                \"turn\": 1,\n                \"response_a\": \"It is possible that your parent did not invite you to their wedding for a variety of reasons. It could be that they did not want to burden you with the planning or expense of the event, or they may not have had the time or resources to include you. Additionally, it could be that they did not feel comfortable having you attend due to your age or relationship with them. It is important to remember that your parent may have had their own reasons for not inviting you, and it is not your place to judge their choices. If you feel neglected or upset about not being invited, it is best to talk to them about it and express your feelings in a non-accusatory way.\",\n                \"response_b\": \"It is likely that they wanted to keep the guest list small and intimate. Maybe they felt that inviting you would make the event too crowded, or that they wanted to keep the event reserved for close friends and family. It could be that they wanted to avoid any potential drama or conflict that could arise from having too many people at the event. Whatever the reason, it's important to remember that they made this decision out of love and respect for you, and that their decision doesn't define your relationship.\",\n                \"token_usage\": {\n                    \"turns\": [\n                        {\n                            \"turn_number\": 1,\n                            \"timestamp_offset\": 0.0,\n                            \"input_tokens\": 11,\n                            \"input_length\": 49,\n                            \"response_a_tokens\": 139,\n                            \"response_a_length\": 660,\n                            \"response_b_tokens\": 100,\n                            \"response_b_length\": 514\n                        }\n                    ],\n                    \"total_input_tokens\": 150,\n                    \"total_output_tokens_a\": 139,\n                    \"total_output_tokens_b\": 100,\n                    \"total_tokens\": 389,\n                    \"message_lengths\": {\n                        \"input\": [49, 660],\n                        \"response_a\": [660],\n                        \"response_b\": [514]\n                    },\n                    \"communication_efficiency\": {\n                        \"avg_tokens_per_turn\": 194.5,\n                        \"input_output_ratio\": 0.3856041131105398,\n                        \"coordination_overhead\": 0.10025706940874037\n                    }\n                },\n                \"api_metadata\": {\n                    \"question_id\": \"2564acd09e3942fd97657d05282d4389\",\n                    \"timestamp\": 1682351654.6747,\n                    \"toxic_chat_tag\": {\n                        \"roberta-large\": {\"flagged\": False, \"probability\": 0.038766861},\n                        \"t5-large\": {\"flagged\": False, \"score\": 0.0017759029}\n                    },\n                    \"anony\": True\n                }\n            },\n            \"output\": \"Winner: tie\",\n            \"dataset\": \"lmsys/chatbot_arena_conversations\", \n            \"split\": \"train\"\n        },\n        {\n            \"input\": \"Fuji vs. Nikon, which is better?\",\n            \"context\": {\n                \"model_a\": \"koala-13b\",\n                \"model_b\": \"oasst-pythia-12b\",\n                \"winner\": \"model_b\",\n                \"judge\": \"arena_user_973\",\n                \"language\": \"English\",\n                \"turn\": 1,\n                \"response_a\": \"Both Fuji and Nikon are popular camera brands that offer a wide range of cameras for different types of photography. It really depends on your specific needs and preferences as to which brand is \\\\\"better\\\\\" for you.\\\\n\\\\nFujifilm is known for its high image quality, especially in the areas of color accuracy and dynamic range. Many photographers also appreciate the company's focus on ergonomics and the overall user experience of its cameras. Additionally, Fujifilm has a loyal following among enthusiasts and professional photographers, thanks to its commitment to film photography and its high-end mirrorless cameras.\\\\n\\\\nNikon, on the other hand, is known for its advanced autofocus system and image stabilization technology, as well as its high-end cameras and lenses. Nikon also has a wide selection of cameras and lenses to choose from, including both DSLR and mirrorless options.\\\\n\\\\nUltimately, it's difficult to say which brand is \\\\\"better\\\\\" without knowing more about your specific needs and preferences. It might be helpful to research both brands further and try out a few different models before making a decision.\",\n                \"response_b\": \"This is a subjective question and the answer depends on the individual preferences and needs. Both Fujifilm and Nikon are well-known for their high-quality cameras, and the choice between the two ultimately depends on the user's personal preferences and needs.\",\n                \"token_usage\": {\n                    \"turns\": [\n                        {\n                            \"turn_number\": 1,\n                            \"timestamp_offset\": 0.0,\n                            \"input_tokens\": 10,\n                            \"input_length\": 32,\n                            \"response_a_tokens\": 212,\n                            \"response_a_length\": 1114,\n                            \"response_b_tokens\": 309,\n                            \"response_b_length\": 1566\n                        }\n                    ],\n                    \"total_input_tokens\": 222,\n                    \"total_output_tokens_a\": 212,\n                    \"total_output_tokens_b\": 309,\n                    \"total_tokens\": 743,\n                    \"message_lengths\": {\n                        \"input\": [32, 1114],\n                        \"response_a\": [1114],\n                        \"response_b\": [1566]\n                    },\n                    \"communication_efficiency\": {\n                        \"avg_tokens_per_turn\": 371.5,\n                        \"input_output_ratio\": 0.29878869448183043,\n                        \"coordination_overhead\": 0.13055181695827725\n                    }\n                },\n                \"api_metadata\": {\n                    \"question_id\": \"90bfd142157948aba01931726c888e7f\",\n                    \"timestamp\": 1682351708.9351,\n                    \"toxic_chat_tag\": {\n                        \"roberta-large\": {\"flagged\": False, \"probability\": 0.0259171631},\n                        \"t5-large\": {\"flagged\": False, \"score\": 0.00019426}\n                    },\n                    \"anony\": True\n                }\n            },\n            \"output\": \"Winner: model_b\",\n            \"dataset\": \"lmsys/chatbot_arena_conversations\",\n            \"split\": \"train\"\n        }\n    ]\n}\n\nprint(f\"üìä Loaded sample dataset with {len(sample_data['examples'])} examples\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Sample Dataset\n\nHere's our sample dataset with 3 examples from the LMSYS ChatBot Arena conversations. Each example contains:\n\n- **Input**: User query\n- **Context**: Model comparison data including responses, token usage, and metadata\n- **Output**: Coordination outcome (winner)\n- **Dataset**: Source dataset identifier\n- **Split**: Train/test split designation",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Import required libraries\nimport json\nfrom pathlib import Path\nfrom typing import Any, Dict, List\nimport pprint\n\nprint(\"üì¶ Libraries imported successfully!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Annotated Low-Rank Coordinator Interaction Dataset\n\nThis interactive notebook demonstrates the **Multi-LLM Agent Coordination Dataset Curation Script** that processes multi-LLM conversation data and creates standardized outputs for coordination analysis.\n\n## Dataset Objective\n\nThe script processes coordination data with the following features:\n- ‚úÖ **Token-level communication logs**: Already available in the dataset\n- ‚ö†Ô∏è **Low-rank recurrent coordinator latent states**: To be added in annotation phase  \n- ‚ö†Ô∏è **Explicit coordination outcome labels**: To be added in annotation phase\n\n## Key Features\n\n- Standardizes multi-LLM conversation data from LMSYS ChatBot Arena\n- Tracks token usage and communication efficiency metrics\n- Analyzes model coordination outcomes and winner distributions\n- Provides structured data for downstream ML research\n\nLet's explore how this dataset curation pipeline works!",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}