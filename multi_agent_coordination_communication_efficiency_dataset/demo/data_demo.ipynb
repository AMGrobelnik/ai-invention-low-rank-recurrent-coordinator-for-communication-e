{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "## Dataset Usage and Extensions\n\nThis notebook demonstrates how to process and analyze multi-agent LLM interaction data. Here are some ways you can extend this work:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "def analyze_response_quality(examples):\n    \"\"\"Analyze response characteristics and quality indicators.\"\"\"\n    analysis = {\n        'response_lengths': {'a': [], 'b': []},\n        'model_performance': {},\n        'question_types': {},\n        'language_distribution': {}\n    }\n    \n    for example in examples:\n        context = example['context']\n        \n        # Response lengths\n        resp_a_len = len(context['response_a'])\n        resp_b_len = len(context['response_b'])\n        analysis['response_lengths']['a'].append(resp_a_len)\n        analysis['response_lengths']['b'].append(resp_b_len)\n        \n        # Model performance tracking\n        model_a = context['model_a']\n        model_b = context['model_b']\n        winner = context['winner']\n        \n        for model in [model_a, model_b]:\n            if model not in analysis['model_performance']:\n                analysis['model_performance'][model] = {'wins': 0, 'losses': 0, 'ties': 0, 'total': 0}\n        \n        analysis['model_performance'][model_a]['total'] += 1\n        analysis['model_performance'][model_b]['total'] += 1\n        \n        if winner == 'model_a':\n            analysis['model_performance'][model_a]['wins'] += 1\n            analysis['model_performance'][model_b]['losses'] += 1\n        elif winner == 'model_b':\n            analysis['model_performance'][model_b]['wins'] += 1\n            analysis['model_performance'][model_a]['losses'] += 1\n        elif winner == 'tie':\n            analysis['model_performance'][model_a]['ties'] += 1\n            analysis['model_performance'][model_b]['ties'] += 1\n        \n        # Language distribution\n        language = context.get('language', 'Unknown')\n        analysis['language_distribution'][language] = analysis['language_distribution'].get(language, 0) + 1\n        \n        # Simple question type classification\n        question = example['input'].lower()\n        if 'what' in question or 'how' in question:\n            qtype = 'informational'\n        elif 'why' in question:\n            qtype = 'explanatory'\n        elif 'vs' in question or 'better' in question:\n            qtype = 'comparative'\n        else:\n            qtype = 'other'\n        \n        analysis['question_types'][qtype] = analysis['question_types'].get(qtype, 0) + 1\n    \n    return analysis\n\n# Perform analysis\nprint(\"üî¨ Analyzing Multi-Agent Response Patterns...\")\nanalysis = analyze_response_quality(processed_examples)\n\nprint(f\"\\\\n{CYAN}üìè Response Length Analysis:{END}\")\navg_len_a = sum(analysis['response_lengths']['a']) / len(analysis['response_lengths']['a'])\navg_len_b = sum(analysis['response_lengths']['b']) / len(analysis['response_lengths']['b'])\nprint(f\"  Average Model A response length: {avg_len_a:.0f} characters\")\nprint(f\"  Average Model B response length: {avg_len_b:.0f} characters\")\n\nprint(f\"\\\\n{CYAN}üèÜ Model Performance Summary:{END}\")\nfor model, stats in analysis['model_performance'].items():\n    win_rate = stats['wins'] / stats['total'] * 100 if stats['total'] > 0 else 0\n    print(f\"  {model}: {win_rate:.1f}% win rate ({stats['wins']}/{stats['total']} matches)\")\n\nprint(f\"\\\\n{CYAN}‚ùì Question Type Distribution:{END}\")\nfor qtype, count in analysis['question_types'].items():\n    print(f\"  {qtype.capitalize()}: {count} questions\")\n\nprint(f\"\\\\n{CYAN}üåç Language Distribution:{END}\")\nfor lang, count in analysis['language_distribution'].items():\n    print(f\"  {lang}: {count} examples\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Interactive Data Exploration\n\nLet's add some interactive features to explore the dataset further and understand the multi-agent dynamics.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Create the final dataset structure\noutput_data = {\n    \"examples\": processed_examples\n}\n\nprint(f\"{BLUE}Final Dataset Statistics:{END}\")\nprint(f\"  Total examples: {len(output_data['examples'])}\")\nprint(f\"  Dataset source: lmsys/chatbot_arena_conversations\")\nprint(f\"  Focus: Multi-LLM agent interaction and coordination\")\nprint()\n\n# Show the JSON structure (pretty formatted)\nprint(f\"{BLUE}Sample JSON Output Structure:{END}\")\nprint(\"=\" * 60)\nsample_output = {\n    \"examples\": [output_data[\"examples\"][0]]  # Just show first example\n}\n\n# Pretty print the JSON structure\nimport json\nprint(json.dumps(sample_output, indent=2, ensure_ascii=False)[:1000] + \"...\")\n\nprint(f\"\\\\n{GREEN}‚úÖ Dataset processing complete!{END}\")\nprint(f\"This dataset can be used for research into:\")\nprint(\"  ‚Ä¢ Multi-agent coordination patterns\")\nprint(\"  ‚Ä¢ Communication efficiency between LLMs\")\nprint(\"  ‚Ä¢ Model comparison and evaluation methods\")\nprint(\"  ‚Ä¢ Preference learning and ranking\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Generate Final Dataset Output\n\nNow let's create the final output structure that matches the original script's format.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Let's examine the first processed example in detail\nprint(\"üîç First Processed Example Structure:\")\nprint(\"=\" * 60)\nfirst_example = processed_examples[0]\n\nprint(f\"{CYAN}Input (User Question):{END}\")\nprint(f\"  {first_example['input'][:100]}...\")\nprint()\n\nprint(f\"{CYAN}Context (Multi-Agent Metadata):{END}\")\nfor key, value in first_example['context'].items():\n    if key in ['response_a', 'response_b']:\n        print(f\"  {key}: {str(value)[:100]}...\")\n    else:\n        print(f\"  {key}: {value}\")\nprint()\n\nprint(f\"{CYAN}Output (Winner Decision):{END}\")\nprint(f\"  {first_example['output']}\")\nprint()\n\nprint(f\"{CYAN}Dataset Info:{END}\")\nprint(f\"  Dataset: {first_example['dataset']}\")\nprint(f\"  Split: {first_example['split']}\")\nprint()\n\n# Show comparison of models\nprint(\"üèÜ Model Comparison Analysis:\")\nprint(\"=\" * 60)\nfor i, example in enumerate(processed_examples):\n    model_a = example['context']['model_a']\n    model_b = example['context']['model_b']\n    winner = example['context']['winner']\n    \n    print(f\"Example {i+1}: {model_a} vs {model_b} ‚Üí Winner: {winner}\")\n\n# Summary statistics\nwinners = [ex['context']['winner'] for ex in processed_examples]\nwinner_counts = {}\nfor winner in winners:\n    winner_counts[winner] = winner_counts.get(winner, 0) + 1\n\nprint(f\"\\\\nüìä Winner Distribution:\")\nfor winner, count in winner_counts.items():\n    print(f\"  {winner}: {count} examples\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Explore Processed Data\n\nLet's examine the structure of our processed data to understand how the standardization works.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "def process_chatbot_arena(data: List[Dict], limit: int = 200) -> List[Dict]:\n    \"\"\"\n    Process lmsys/chatbot_arena_conversations dataset.\n    \n    This function transforms raw chatbot arena data into a standardized format\n    that focuses on multi-LLM agent interactions and comparisons.\n    \n    Args:\n        data: List of raw chatbot arena conversation records\n        limit: Maximum number of examples to process\n    \n    Returns:\n        List of processed examples in standardized format\n    \"\"\"\n    print(f\"{YELLOW}Processing{END} chatbot_arena_conversations\")\n    examples = []\n\n    for item in data[:limit]:\n        # Extract conversation from both models\n        conv_a = item.get(\"conversation_a\", [])\n        conv_b = item.get(\"conversation_b\", [])\n\n        if not conv_a or not conv_b:\n            continue\n\n        # Build multi-turn conversation as input\n        user_msg = conv_a[0].get(\"content\", \"\") if conv_a else \"\"\n        response_a = conv_a[1].get(\"content\", \"\") if len(conv_a) > 1 else \"\"\n        response_b = conv_b[1].get(\"content\", \"\") if len(conv_b) > 1 else \"\"\n\n        # Create structured example\n        example = {\n            \"input\": user_msg,\n            \"context\": {\n                \"model_a\": item.get(\"model_a\", \"\"),\n                \"model_b\": item.get(\"model_b\", \"\"),\n                \"winner\": item.get(\"winner\", \"\"),\n                \"judge\": item.get(\"judge\", \"\"),\n                \"language\": item.get(\"language\", \"\"),\n                \"turn\": item.get(\"turn\", 1),\n                \"response_a\": response_a,\n                \"response_b\": response_b\n            },\n            \"output\": f\"Winner: {item.get('winner', 'unknown')}\",\n            \"dataset\": \"lmsys/chatbot_arena_conversations\",\n            \"split\": \"train\"\n        }\n        examples.append(example)\n\n    print(f\"{GREEN}Processed{END} {len(examples)} examples from chatbot_arena\")\n    return examples\n\n# Test the function with our sample data\nprocessed_examples = process_chatbot_arena(sample_chatbot_arena_data, limit=10)\nprint(f\"\\\\n‚úÖ Successfully processed {len(processed_examples)} examples\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Data Processing Functions\n\nNow let's implement the core data processing functions from the original script. These functions transform the raw chatbot arena data into a standardized format suitable for multi-agent coordination research.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Sample raw chatbot arena data (simulating what would be loaded from external JSON files)\n# This data represents conversations where two different LLMs compete to answer questions\n# and a judge determines the winner\n\nsample_chatbot_arena_data = [\n    {\n        \"conversation_a\": [\n            {\n                \"content\": \"What is the difference between OpenCL and CUDA?\"\n            },\n            {\n                \"content\": \"OpenCL and CUDA are two different programming models that are used for parallel computing.OpenCL is a general-purposeÂπ∂Ë°åÁºñÁ®ãÊé•Âè£ that allows developers to write parallel code that can run on any platform that supportsCL, which includes most modern operating systems and computer systems, including Windows, Linux, and macOS. It provides a lower-level, more flexible API that is more suitable for building large-scale distributed computing systems.CUDA is a specific implementation ofOpenCL that is designed for performance and scalability in devices with multiple GPU(s). It was developed by Nvidia and is widely used for scientific computing, machine learning, andÂõæÂΩ¢ÂõæÂÉèÂ§ÑÁêÜ. The CUDA API provides a high-level, more efficient way to write parallel code that can run on top of a GPU, while still maintaining the ability to write code that can be easily adapted for other parallel computing platforms.\"\n            }\n        ],\n        \"conversation_b\": [\n            {\n                \"content\": \"What is the difference between OpenCL and CUDA?\"\n            },\n            {\n                \"content\": \"OpenCL and CUDA are both programming languages for parallel computing on GPUs, but they differ in several key ways:\\n\\n1.   Architecture: OpenCL is a general-purpose parallel computing language, while CUDA is designed specifically for GPU computing. OpenCL can run on various types of processors, including CPUs, GPUs, and FPGAs, whereas CUDA is only compatible with NVIDIA GPUs.\\n2.   Language: OpenCL is a C++ language, while CUDA is a C++ language with additional features for GPU computing. CUDA provides additional libraries and tools for handling graphics and other tasks unique to GPUs.\\n3.   Driver support: OpenCL has a wider range of device support, with support for not just NVIDIA GPUs but also other manufacturers like AMD, Intel, and ARM. CUDA is only available on NVIDIA GPUs, and requires the CUDA Toolkit to be installed on the host machine.\\n4.   Memory management: OpenCL provides a unified memory model, where all the data is stored in global memory, and the kernel can access any part of it. CUDA, on the other hand, uses a hierarchical memory architecture, where data is divided into host, device, and shared memory.\\n5.   Performance: OpenCL and CUDA have different strengths and weaknesses in terms of performance. OpenCL is generally faster for numerical computations, while CUDA is faster for graphics and other tasks that require fast memory access. CUDA also has better support for 64-bit floating-point operations, which are essential for some scientific applications.\\n\\nIn summary, OpenCL and CUDA are both programming languages for parallel computing on GPUs, but they differ in terms of architecture, language, driver support, memory management, and performance. OpenCL is a general-purpose language that can run on various types of processors, while CUDA is specific to NVIDIA GPUs and provides additional libraries and tools for handling graphics and other tasks unique to GPUs.\"\n            }\n        ],\n        \"model_a\": \"chatglm-6b\",\n        \"model_b\": \"koala-13b\",\n        \"winner\": \"model_b\",\n        \"judge\": \"arena_user_973\",\n        \"language\": \"English\",\n        \"turn\": 1\n    },\n    {\n        \"conversation_a\": [\n            {\n                \"content\": \"Why did my parent not invite me to their wedding?\"\n            },\n            {\n                \"content\": \"It is possible that your parent did not invite you to their wedding for a variety of reasons. It could be that they did not want to burden you with the planning or expense of the event, or they may not have had the time or resources to include you. Additionally, it could be that they did not feel comfortable having you attend due to your age or relationship with them. It is important to remember that your parent may have had their own reasons for not inviting you, and it is not your place to judge their choices. If you feel neglected or upset about not being invited, it is best to talk to them about it and express your feelings in a non-accusatory way.\"\n            }\n        ],\n        \"conversation_b\": [\n            {\n                \"content\": \"Why did my parent not invite me to their wedding?\"\n            },\n            {\n                \"content\": \"It is likely that they wanted to keep the guest list small and intimate. Maybe they felt that inviting you would make the event too crowded, or that they wanted to keep the event reserved for close friends and family. It could be that they wanted to avoid any potential drama or conflict that could arise from having too many people at the event. Whatever the reason, it's important to remember that they made this decision out of love and respect for you, and that their decision doesn't define your relationship.\"\n            }\n        ],\n        \"model_a\": \"oasst-pythia-12b\",\n        \"model_b\": \"alpaca-13b\",\n        \"winner\": \"tie\",\n        \"judge\": \"arena_user_973\",\n        \"language\": \"English\",\n        \"turn\": 1\n    },\n    {\n        \"conversation_a\": [\n            {\n                \"content\": \"Fuji vs. Nikon, which is better?\"\n            },\n            {\n                \"content\": \"Both Fuji and Nikon are popular camera brands that offer a wide range of cameras for different types of photography. It really depends on your specific needs and preferences as to which brand is \\\"better\\\" for you.\\n\\nFujifilm is known for its high image quality, especially in the areas of color accuracy and dynamic range. Many photographers also appreciate the company's focus on ergonomics and the overall user experience of its cameras. Additionally, Fujifilm has a loyal following among enthusiasts and professional photographers, thanks to its commitment to film photography and its high-end mirrorless cameras.\\n\\nNikon, on the other hand, is known for its advanced autofocus system and image stabilization technology, as well as its high-end cameras and lenses. Nikon also has a wide selection of cameras and lenses to choose from, including both DSLR and mirrorless options.\\n\\nUltimately, it's difficult to say which brand is \\\"better\\\" without knowing more about your specific needs and preferences. It might be helpful to research both brands further and try out a few different models before making a decision.\"\n            }\n        ],\n        \"conversation_b\": [\n            {\n                \"content\": \"Fuji vs. Nikon, which is better?\"\n            },\n            {\n                \"content\": \"This is a subjective question and the answer depends on the individual preferences and needs. Both Fujifilm and Nikon are well-known for their high-quality cameras, and the choice between the two ultimately depends on the user's personal preferences and needs.\\n\\nSome factors to consider when deciding between a Fuji and a Nikon camera include:\\n\\n1. Image quality: Fuji cameras are known for their high-quality images, with a distinctive film-like quality. Nikon cameras are also notable for their image quality, but they may not offer the same level of sharpness and color accuracy as Fuji cameras.\\n\\n2. Focusing: Fuji cameras are known for their fast and precise autofocus, while Nikon cameras tend to have a slower and more manual focus system.\\n\\n3. Image size: Fuji cameras are known for their wide range of photo sizes, from small compacts to large-format cameras. Nikon cameras are also capable of producing high-quality images, but they may not be as versatile as Fuji cameras.\\n\\n4. User interface: Fuji cameras have a user-friendly interface, with a simplified design that is easy to navigate. Nikon cameras may have a more complex interface, but they also offer a wealth of features and customization options.\\n\\nUltimately, the best camera for you will depend on your specific needs and preferences. If you're looking for a high-quality camera that offers a unique film-like experience, a Fuji camera may be the right choice for you. If you're looking for a camera that is easy to use and offers a wide range of photo sizes, a Nikon camera may be the best choice.\"\n            }\n        ],\n        \"model_a\": \"koala-13b\",\n        \"model_b\": \"oasst-pythia-12b\",\n        \"winner\": \"model_b\",\n        \"judge\": \"arena_user_973\",\n        \"language\": \"English\",\n        \"turn\": 1\n    }\n]\n\nprint(f\"üìä Sample data loaded: {len(sample_chatbot_arena_data)} examples\")\nprint(\"üîç Each example contains conversation between two models with winner judgment\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Sample Data\n\nInstead of loading from external files, we'll inline some sample data from the chatbot arena conversations dataset. This makes the notebook completely self-contained.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Import required libraries\nimport json\nimport sys\nfrom typing import Any, Dict, List\nfrom pprint import pprint\n\n# Define color constants for formatted output\nBLUE, GREEN, YELLOW, CYAN, END = \"\\033[94m\", \"\\033[92m\", \"\\033[93m\", \"\\033[96m\", \"\\033[0m\"\n\nprint(\"‚úÖ Imports completed successfully!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Multi-Agent Coordination Communication-Efficiency Dataset\n\nThis notebook demonstrates the processing of multi-LLM agent interaction datasets. The original script loads and processes data from the lmsys/chatbot_arena_conversations dataset to create a standardized format for studying multi-agent coordination and communication patterns.\n\n## Overview\n\nThis dataset processing script:\n- Loads chatbot arena conversation data\n- Standardizes the format to match a specific schema\n- Extracts conversation examples with model comparisons\n- Focuses on multi-LLM agent interactions and their evaluation\n\nLet's explore the data processing pipeline step by step.",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}