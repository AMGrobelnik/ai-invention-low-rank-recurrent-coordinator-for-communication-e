{
  "title": "Multi-LLM Agent Coordination Dataset with Token Metadata",
  "summary": "This artifact contains 200 multi-LLM agent interaction episodes from lmsys/chatbot_arena_conversations enriched with detailed token-usage metadata for communication-efficiency evaluation. Each example includes user inputs, responses from two language models (model_a and model_b), per-turn token counts computed using tiktoken cl100k_base encoding, message lengths, timestamps, communication efficiency metrics (avg_tokens_per_turn, input_output_ratio, coordination_overhead), total token usage (average 663.3 tokens per example), and human-evaluated performance labels. Key outputs: data_out.json (200 examples, 759KB), full_data_out.json (identical copy), mini_data_out.json (3 examples for testing), preview_data_out.json (3 truncated examples), and data.py (reproducible processing script). Downstream artifacts can use this dataset to: compute baseline token overhead for multi-agent coordination, evaluate low-rank compression strategies, measure communication savings while preserving task quality, analyze per-turn efficiency patterns, and benchmark model-agnostic coordination methods. The dataset covers 48 unique model pairs with balanced winner distribution across diverse interaction scenarios."
}
