{
 "cells": [
  {
   "cell_type": "code",
   "source": "# Analyze communication efficiency across examples\ndef analyze_efficiency_patterns(examples):\n    \"\"\"Analyze communication efficiency patterns across the dataset.\"\"\"\n    \n    if not examples:\n        print(\"No examples to analyze\")\n        return\n    \n    print(f\"{CYAN}=== COMMUNICATION EFFICIENCY ANALYSIS ==={END}\")\n    print(f\"Analyzing {len(examples)} conversation examples\\\\n\")\n    \n    # Extract efficiency metrics\n    total_tokens = []\n    avg_tokens_per_turn = []\n    input_output_ratios = []\n    coordination_overheads = []\n    model_pairs = []\n    winners = []\n    \n    for example in examples:\n        token_usage = example['context']['token_usage']\n        efficiency = token_usage['communication_efficiency']\n        \n        total_tokens.append(token_usage['total_tokens'])\n        avg_tokens_per_turn.append(efficiency['avg_tokens_per_turn'])\n        input_output_ratios.append(efficiency['input_output_ratio'])\n        coordination_overheads.append(efficiency['coordination_overhead'])\n        \n        model_pair = f\"{example['context']['model_a']} vs {example['context']['model_b']}\"\n        model_pairs.append(model_pair)\n        winners.append(example['context']['winner'])\n    \n    # Calculate statistics\n    print(f\"{BLUE}Token Usage Statistics:{END}\")\n    print(f\"  Average total tokens: {sum(total_tokens)/len(total_tokens):.1f}\")\n    print(f\"  Min total tokens: {min(total_tokens)}\")\n    print(f\"  Max total tokens: {max(total_tokens)}\")\n    print()\n    \n    print(f\"{BLUE}Efficiency Metrics:{END}\")\n    print(f\"  Avg tokens per turn: {sum(avg_tokens_per_turn)/len(avg_tokens_per_turn):.1f}\")\n    print(f\"  Avg input/output ratio: {sum(input_output_ratios)/len(input_output_ratios):.3f}\")\n    print(f\"  Avg coordination overhead: {sum(coordination_overheads)/len(coordination_overheads):.3f}\")\n    print()\n    \n    print(f\"{BLUE}Model Performance:{END}\")\n    winner_counts = {}\n    for winner in winners:\n        winner_counts[winner] = winner_counts.get(winner, 0) + 1\n    \n    for winner, count in winner_counts.items():\n        percentage = (count / len(winners)) * 100\n        print(f\"  {winner}: {count} ({percentage:.1f}%)\")\n    print()\n    \n    print(f\"{BLUE}Model Pairs in Dataset:{END}\")\n    unique_pairs = set(model_pairs)\n    for pair in unique_pairs:\n        count = model_pairs.count(pair)\n        print(f\"  {pair}: {count} conversations\")\n\n# Run the analysis\nanalyze_efficiency_patterns(enriched_examples)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Analyze Communication Efficiency Across Examples\n\nLet's analyze the communication efficiency patterns across all processed examples:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import json\n\n# Display the first example in a readable format\nif enriched_examples:\n    example = enriched_examples[0]\n    \n    print(f\"{CYAN}=== EXAMPLE STRUCTURE ==={END}\")\n    print(f\"{BLUE}Input:{END} {example['input'][:100]}...\")\n    print(f\"{BLUE}Models:{END} {example['context']['model_a']} vs {example['context']['model_b']}\")\n    print(f\"{BLUE}Winner:{END} {example['context']['winner']}\")\n    print()\n    \n    print(f\"{CYAN}=== TOKEN USAGE METADATA ==={END}\")\n    token_usage = example['context']['token_usage']\n    \n    print(f\"{BLUE}Total Tokens:{END}\")\n    print(f\"  Input tokens: {token_usage['total_input_tokens']}\")\n    print(f\"  Model A output: {token_usage['total_output_tokens_a']}\")\n    print(f\"  Model B output: {token_usage['total_output_tokens_b']}\")\n    print(f\"  Total: {token_usage['total_tokens']}\")\n    print()\n    \n    print(f\"{BLUE}Communication Efficiency:{END}\")\n    efficiency = token_usage['communication_efficiency']\n    print(f\"  Avg tokens per turn: {efficiency['avg_tokens_per_turn']:.1f}\")\n    print(f\"  Input/output ratio: {efficiency['input_output_ratio']:.3f}\")\n    print(f\"  Coordination overhead: {efficiency['coordination_overhead']:.3f}\")\n    print()\n    \n    print(f\"{BLUE}Per-turn Analysis:{END}\")\n    for turn in token_usage['turns']:\n        print(f\"  Turn {turn['turn_number']}: {turn.get('input_tokens', 0)} in → \"\n              f\"{turn.get('response_a_tokens', 0)} (A) + {turn.get('response_b_tokens', 0)} (B) out\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Examine Example Structure\n\nLet's look at the structure of one enriched example to understand the token usage metadata:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Process the sample dataset\nenriched_examples = process_chatbot_arena_with_tokens(sample_chatbot_arena_data, limit=10)\n\nprint(f\"\\\\n{GREEN}Dataset Processing Complete!{END}\")\nprint(f\"Generated {len(enriched_examples)} enriched examples\")\nprint(f\"Each example includes:\")\nprint(\"  ✓ Original conversation data\")\nprint(\"  ✓ Detailed token usage metadata\") \nprint(\"  ✓ Communication efficiency metrics\")\nprint(\"  ✓ API metadata and timestamps\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Process the Dataset\n\nLet's run the processing function on our sample data and examine the results:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "def process_chatbot_arena_with_tokens(data: List[Dict], limit: int = 200) -> List[Dict]:\n    \"\"\"\n    Process lmsys/chatbot_arena_conversations dataset with token usage enrichment.\n\n    This adds detailed per-turn token counts, message lengths, and API-call metadata\n    to enable communication-efficiency evaluation.\n    \"\"\"\n    print(f\"{YELLOW}Processing{END} chatbot_arena with token enrichment (target: {limit} examples)\")\n    examples = []\n\n    for idx, item in enumerate(data):\n        if len(examples) >= limit:\n            break\n\n        # Extract conversations\n        conv_a = item.get(\"conversation_a\", [])\n        conv_b = item.get(\"conversation_b\", [])\n\n        if not conv_a or not conv_b or len(conv_a) < 2 or len(conv_b) < 2:\n            continue\n\n        # Extract first user message\n        user_msg = conv_a[0].get(\"content\", \"\") if conv_a else \"\"\n        response_a = conv_a[1].get(\"content\", \"\") if len(conv_a) > 1 else \"\"\n        response_b = conv_b[1].get(\"content\", \"\") if len(conv_b) > 1 else \"\"\n\n        if not user_msg or not response_a or not response_b:\n            continue\n\n        # Compute token usage metadata\n        token_metadata = compute_token_metadata(conv_a, conv_b)\n\n        # Create enriched example\n        example = {\n            \"input\": user_msg,\n            \"context\": {\n                \"model_a\": item.get(\"model_a\", \"\"),\n                \"model_b\": item.get(\"model_b\", \"\"),\n                \"winner\": item.get(\"winner\", \"\"),\n                \"judge\": item.get(\"judge\", \"\"),\n                \"language\": item.get(\"language\", \"\"),\n                \"turn\": item.get(\"turn\", 1),\n                \"response_a\": response_a,\n                \"response_b\": response_b,\n                # TOKEN USAGE METADATA (NEW)\n                \"token_usage\": token_metadata,\n                \"api_metadata\": {\n                    \"question_id\": item.get(\"question_id\", \"\"),\n                    \"timestamp\": item.get(\"tstamp\", time.time()),\n                    \"toxic_chat_tag\": item.get(\"toxic_chat_tag\", False),\n                    \"anony\": item.get(\"anony\", True)\n                }\n            },\n            \"output\": f\"Winner: {item.get('winner', 'unknown')}\",\n            \"dataset\": \"lmsys/chatbot_arena_conversations\",\n            \"split\": \"train\"\n        }\n        examples.append(example)\n\n    print(f\"{GREEN}Processed{END} {len(examples)} enriched examples with token metadata\")\n    return examples\n\nprint(\"✓ Dataset processing function defined\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Dataset Processing Function\n\nNow let's define the main processing function that enriches the conversation data with token usage metadata:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Sample dataset - inline data to make notebook self-contained\nsample_chatbot_arena_data = [\n    {\n        \"question_id\": \"58210e39b3fd4441a2bd4a518bb44c2d\",\n        \"model_a\": \"chatglm-6b\",\n        \"model_b\": \"koala-13b\",\n        \"winner\": \"model_b\",\n        \"judge\": \"arena_user_973\",\n        \"language\": \"English\",\n        \"turn\": 1,\n        \"tstamp\": 1682351591.1322,\n        \"conversation_a\": [\n            {\n                \"content\": \"What is the difference between OpenCL and CUDA?\",\n                \"role\": \"user\"\n            },\n            {\n                \"content\": \"OpenCL and CUDA are two different programming models that are used for parallel computing.OpenCL is a general-purpose并行编程接口 that allows developers to write parallel code that can run on any platform that supportsCL, which includes most modern operating systems and computer systems, including Windows, Linux, and macOS. It provides a lower-level, more flexible API that is more suitable for building large-scale distributed computing systems.CUDA is a specific implementation ofOpenCL that is designed for performance and scalability in devices with multiple GPU(s). It was developed by Nvidia and is widely used for scientific computing, machine learning, and图形图像处理. The CUDA API provides a high-level, more efficient way to write parallel code that can run on top of a GPU, while still maintaining the ability to write code that can be easily adapted for other parallel computing platforms.\",\n                \"role\": \"assistant\"\n            }\n        ],\n        \"conversation_b\": [\n            {\n                \"content\": \"What is the difference between OpenCL and CUDA?\",\n                \"role\": \"user\"\n            },\n            {\n                \"content\": \"OpenCL and CUDA are both programming languages for parallel computing on GPUs, but they differ in several key ways:\\\\n\\\\n1.   Architecture: OpenCL is a general-purpose parallel computing language, while CUDA is designed specifically for GPU computing. OpenCL can run on various types of processors, including CPUs, GPUs, and FPGAs, whereas CUDA is only compatible with NVIDIA GPUs.\\\\n2.   Language: OpenCL is a C++ language, while CUDA is a C++ language with additional features for GPU computing. CUDA provides additional libraries and tools for handling graphics and other tasks unique to GPUs.\\\\n3.   Driver support: OpenCL has a wider range of device support, with support for not just NVIDIA GPUs but also other manufacturers like AMD, Intel, and ARM. CUDA is only available on NVIDIA GPUs, and requires the CUDA Toolkit to be installed on the host machine.\\\\n4.   Memory management: OpenCL provides a unified memory model, where all the data is stored in global memory, and the kernel can access any part of it. CUDA, on the other hand, uses a hierarchical memory architecture, where data is divided into host, device, and shared memory.\\\\n5.   Performance: OpenCL and CUDA have different strengths and weaknesses in terms of performance. OpenCL is generally faster for numerical computations, while CUDA is faster for graphics and other tasks that require fast memory access. CUDA also has better support for 64-bit floating-point operations, which are essential for some scientific applications.\\\\n\\\\nIn summary, OpenCL and CUDA are both programming languages for parallel computing on GPUs, but they differ in terms of architecture, language, driver support, memory management, and performance. OpenCL is a general-purpose language that can run on various types of processors, while CUDA is specific to NVIDIA GPUs and provides additional libraries and tools for handling graphics and other tasks unique to GPUs.\",\n                \"role\": \"assistant\"\n            }\n        ],\n        \"toxic_chat_tag\": {\n            \"roberta-large\": {\"flagged\": False, \"probability\": 0.0083130226},\n            \"t5-large\": {\"flagged\": False, \"score\": 7.94367e-05}\n        },\n        \"anony\": True\n    },\n    {\n        \"question_id\": \"2564acd09e3942fd97657d05282d4389\",\n        \"model_a\": \"oasst-pythia-12b\",\n        \"model_b\": \"alpaca-13b\",\n        \"winner\": \"tie\",\n        \"judge\": \"arena_user_973\",\n        \"language\": \"English\",\n        \"turn\": 1,\n        \"tstamp\": 1682351654.6747,\n        \"conversation_a\": [\n            {\n                \"content\": \"Why did my parent not invite me to their wedding?\",\n                \"role\": \"user\"\n            },\n            {\n                \"content\": \"It is possible that your parent did not invite you to their wedding for a variety of reasons. It could be that they did not want to burden you with the planning or expense of the event, or they may not have had the time or resources to include you. Additionally, it could be that they did not feel comfortable having you attend due to your age or relationship with them. It is important to remember that your parent may have had their own reasons for not inviting you, and it is not your place to judge their choices. If you feel neglected or upset about not being invited, it is best to talk to them about it and express your feelings in a non-accusatory way.\",\n                \"role\": \"assistant\"\n            }\n        ],\n        \"conversation_b\": [\n            {\n                \"content\": \"Why did my parent not invite me to their wedding?\",\n                \"role\": \"user\"\n            },\n            {\n                \"content\": \"It is likely that they wanted to keep the guest list small and intimate. Maybe they felt that inviting you would make the event too crowded, or that they wanted to keep the event reserved for close friends and family. It could be that they wanted to avoid any potential drama or conflict that could arise from having too many people at the event. Whatever the reason, it's important to remember that they made this decision out of love and respect for you, and that their decision doesn't define your relationship.\",\n                \"role\": \"assistant\"\n            }\n        ],\n        \"toxic_chat_tag\": {\n            \"roberta-large\": {\"flagged\": False, \"probability\": 0.038766861},\n            \"t5-large\": {\"flagged\": False, \"score\": 0.0017759029}\n        },\n        \"anony\": True\n    },\n    {\n        \"question_id\": \"90bfd142157948aba01931726c888e7f\",\n        \"model_a\": \"koala-13b\",\n        \"model_b\": \"oasst-pythia-12b\",\n        \"winner\": \"model_b\",\n        \"judge\": \"arena_user_973\",\n        \"language\": \"English\",\n        \"turn\": 1,\n        \"tstamp\": 1682351708.9351,\n        \"conversation_a\": [\n            {\n                \"content\": \"Fuji vs. Nikon, which is better?\",\n                \"role\": \"user\"\n            },\n            {\n                \"content\": \"Both Fuji and Nikon are popular camera brands that offer a wide range of cameras for different types of photography. It really depends on your specific needs and preferences as to which brand is \\\"better\\\" for you.\\\\n\\\\nFujifilm is known for its high image quality, especially in the areas of color accuracy and dynamic range. Many photographers also appreciate the company's focus on ergonomics and the overall user experience of its cameras. Additionally, Fujifilm has a loyal following among enthusiasts and professional photographers, thanks to its commitment to film photography and its high-end mirrorless cameras.\\\\n\\\\nNikon, on the other hand, is known for its advanced autofocus system and image stabilization technology, as well as its high-end cameras and lenses. Nikon also has a wide selection of cameras and lenses to choose from, including both DSLR and mirrorless options.\\\\n\\\\nUltimately, it's difficult to say which brand is \\\"better\\\" without knowing more about your specific needs and preferences. It might be helpful to research both brands further and try out a few different models before making a decision.\",\n                \"role\": \"assistant\"\n            }\n        ],\n        \"conversation_b\": [\n            {\n                \"content\": \"Fuji vs. Nikon, which is better?\",\n                \"role\": \"user\"\n            },\n            {\n                \"content\": \"This is a subjective question and the answer depends on the individual preferences and needs. Both Fujifilm and Nikon are well-known for their high-quality cameras, and the choice between the two ultimately depends on the user's personal preferences and needs.\\\\n\\\\nSome factors to consider when deciding between a Fuji and a Nikon camera include:\\\\n\\\\n1. Image quality: Fuji cameras are known for their high-quality images, with a distinctive film-like quality. Nikon cameras are also notable for their image quality, but they may not offer the same level of sharpness and color accuracy as Fuji cameras.\\\\n\\\\n2. Focusing: Fuji cameras are known for their fast and precise autofocus, while Nikon cameras tend to have a slower and more manual focus system.\\\\n\\\\n3. Image size: Fuji cameras are known for their wide range of photo sizes, from small compacts to large-format cameras. Nikon cameras are also capable of producing high-quality images, but they may not be as versatile as Fuji cameras.\\\\n\\\\n4. User interface: Fuji cameras have a user-friendly interface, with a simplified design that is easy to navigate. Nikon cameras may have a more complex interface, but they also offer a wealth of features and customization options.\\\\n\\\\nUltimately, the best camera for you will depend on your specific needs and preferences. If you're looking for a high-quality camera that offers a unique film-like experience, a Fuji camera may be the right choice for you. If you're looking for a camera that is easy to use and offers a wide range of photo sizes, a Nikon camera may be the best choice.\",\n                \"role\": \"assistant\"\n            }\n        ],\n        \"toxic_chat_tag\": {\n            \"roberta-large\": {\"flagged\": False, \"probability\": 0.0259171631},\n            \"t5-large\": {\"flagged\": False, \"score\": 0.00019426}\n        },\n        \"anony\": True\n    }\n]\n\nprint(f\"✓ Sample dataset loaded with {len(sample_chatbot_arena_data)} conversation examples\")\nprint(\"Dataset structure:\", list(sample_chatbot_arena_data[0].keys()))",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Sample Dataset\n\nInstead of loading from external files, we'll use sample data inline to make this notebook self-contained. This represents the structure of the lmsys/chatbot_arena_conversations dataset:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "def count_tokens(text: str) -> int:\n    \"\"\"Count tokens in text using tiktoken (cl100k_base encoding for GPT-4).\"\"\"\n    if TIKTOKEN_AVAILABLE:\n        try:\n            encoding = tiktoken.get_encoding(\"cl100k_base\")\n            return len(encoding.encode(text))\n        except Exception as e:\n            print(f\"Failed to use tiktoken: {e}\")\n    \n    # Fallback: approximate as words * 1.3 (common heuristic)\n    return int(len(text.split()) * 1.3)\n\n\ndef compute_token_metadata(conversation_a: List[Dict], conversation_b: List[Dict]) -> Dict[str, Any]:\n    \"\"\"\n    Compute detailed token usage metadata for multi-agent interaction.\n\n    Returns:\n        Dictionary with per-turn token counts, message lengths, and timestamps\n    \"\"\"\n    metadata = {\n        \"turns\": [],\n        \"total_input_tokens\": 0,\n        \"total_output_tokens_a\": 0,\n        \"total_output_tokens_b\": 0,\n        \"total_tokens\": 0,\n        \"message_lengths\": {\n            \"input\": [],\n            \"response_a\": [],\n            \"response_b\": []\n        }\n    }\n\n    # Process each turn\n    for turn_idx in range(max(len(conversation_a), len(conversation_b))):\n        turn_data = {\n            \"turn_number\": turn_idx + 1,\n            \"timestamp_offset\": turn_idx * 5.0  # Simulated 5-second intervals\n        }\n\n        # Get user input (should be same for both models)\n        if turn_idx < len(conversation_a):\n            user_msg = conversation_a[turn_idx].get(\"content\", \"\")\n            turn_data[\"input_tokens\"] = count_tokens(user_msg)\n            turn_data[\"input_length\"] = len(user_msg)\n            metadata[\"total_input_tokens\"] += turn_data[\"input_tokens\"]\n            metadata[\"message_lengths\"][\"input\"].append(len(user_msg))\n\n        # Get response from model A\n        if turn_idx + 1 < len(conversation_a):\n            response_a = conversation_a[turn_idx + 1].get(\"content\", \"\")\n            turn_data[\"response_a_tokens\"] = count_tokens(response_a)\n            turn_data[\"response_a_length\"] = len(response_a)\n            metadata[\"total_output_tokens_a\"] += turn_data[\"response_a_tokens\"]\n            metadata[\"message_lengths\"][\"response_a\"].append(len(response_a))\n\n        # Get response from model B\n        if turn_idx + 1 < len(conversation_b):\n            response_b = conversation_b[turn_idx + 1].get(\"content\", \"\")\n            turn_data[\"response_b_tokens\"] = count_tokens(response_b)\n            turn_data[\"response_b_length\"] = len(response_b)\n            metadata[\"total_output_tokens_b\"] += turn_data[\"response_b_tokens\"]\n            metadata[\"message_lengths\"][\"response_b\"].append(len(response_b))\n\n        metadata[\"turns\"].append(turn_data)\n\n    # Compute total tokens (input + both agent outputs)\n    metadata[\"total_tokens\"] = (\n        metadata[\"total_input_tokens\"] +\n        metadata[\"total_output_tokens_a\"] +\n        metadata[\"total_output_tokens_b\"]\n    )\n\n    # Compute communication efficiency metrics\n    metadata[\"communication_efficiency\"] = {\n        \"avg_tokens_per_turn\": metadata[\"total_tokens\"] / max(len(metadata[\"turns\"]), 1),\n        \"input_output_ratio\": metadata[\"total_input_tokens\"] / max(metadata[\"total_tokens\"], 1),\n        \"coordination_overhead\": abs(metadata[\"total_output_tokens_a\"] - metadata[\"total_output_tokens_b\"]) / max(metadata[\"total_tokens\"], 1)\n    }\n\n    return metadata\n\nprint(\"✓ Token counting and metadata functions defined\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Core Functions\n\nLet's define the core functions for token counting and metadata computation.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import json\nimport sys\nimport time\nfrom typing import Any, Dict, List\n\n# Try to import tiktoken for precise token counting, fallback to approximation\ntry:\n    import tiktoken\n    TIKTOKEN_AVAILABLE = True\n    print(\"✓ tiktoken available for precise token counting\")\nexcept ImportError:\n    TIKTOKEN_AVAILABLE = False\n    print(\"⚠ tiktoken not available, using word-based approximation\")\n\n# Define color constants for logging\nBLUE, GREEN, YELLOW, CYAN, END = \"\\033[94m\", \"\\033[92m\", \"\\033[93m\", \"\\033[96m\", \"\\033[0m\"\n\nprint(f\"{GREEN}Environment setup complete!{END}\")\nprint(f\"Using token counting: {'tiktoken (precise)' if TIKTOKEN_AVAILABLE else 'word approximation'}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Setup and Imports\n\nWe'll start by importing the necessary libraries and setting up the environment for dataset processing.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "# Extended Multi-LLM Coordination Dataset with Token‑Usage Annotations\n\nThis notebook demonstrates dataset processing for multi-LLM agent coordination with detailed token usage analysis. The script processes conversations from the lmsys/chatbot_arena_conversations dataset and enriches each example with comprehensive token-usage metadata to enable evaluation of communication efficiency in multi-agent systems.\n\n## Key Features\n\n- **Token Usage Analysis**: Per-turn token counts using tiktoken cl100k_base encoding\n- **Communication Efficiency Metrics**: Average tokens per turn, input/output ratios, coordination overhead\n- **Model Comparison**: Side-by-side responses from different language models with performance evaluation\n- **Rich Metadata**: Timestamps, message lengths, winner labels, and toxicity scores\n\nThis enriched dataset enables research into:\n- Communication efficiency in multi-agent coordination\n- Token overhead analysis for different model pairs\n- Low-rank compression strategies for multi-LLM systems\n- Performance-efficiency trade-offs in collaborative AI",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}