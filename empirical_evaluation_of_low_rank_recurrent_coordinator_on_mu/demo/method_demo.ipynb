{
 "cells": [
  {
   "cell_type": "code",
   "source": "def predict_winner(state: np.ndarray, agent_outputs: List[str], context: Dict) -> str:\n    \"\"\"\n    Predict winner based on coordinator state.\n    \n    This is a simple heuristic - in practice, you would train a classifier.\n    For this experiment, we use a rule-based approach.\n    \"\"\"\n    try:\n        # Extract features from agent outputs\n        len_a = len(agent_outputs[0])\n        len_b = len(agent_outputs[1])\n        \n        # Use state to weight features\n        # Sum of positive state values as \"confidence\"\n        confidence = np.sum(state[state > 0])\n        \n        # Simple heuristic: longer, more detailed response is often better\n        # But weight by coordinator's state confidence\n        score_a = len_a * (1 + confidence * 0.1)\n        score_b = len_b * (1 + confidence * 0.1)\n        \n        # If very close, predict tie\n        if abs(score_a - score_b) < 50:\n            prediction = \"tie\"\n        elif score_a > score_b:\n            prediction = \"model_a\"\n        else:\n            prediction = \"model_b\"\n        \n        logger.debug(f\"  Prediction: {prediction} (score_a={score_a:.1f}, score_b={score_b:.1f}, confidence={confidence:.4f})\")\n        return prediction\n        \n    except Exception as e:\n        logger.error(f\"{RED}Error in predict_winner: {e}{END}\")\n        return \"tie\"  # Default fallback\n\ndef run_experiment(examples: List[Dict], coordinator, tracker: TokenTracker, name: str) -> Tuple[List[str], List[int]]:\n    \"\"\"\n    Run experiment with given coordinator.\n    \n    Args:\n        examples: Dataset examples\n        coordinator: Coordinator instance (FullRank or LowRank)\n        tracker: Token tracker instance  \n        name: Experiment name for logging\n        \n    Returns:\n        Tuple of (predictions, token_counts_per_episode)\n    \"\"\"\n    try:\n        print(f\"\\n{BLUE}{'='*60}{END}\")\n        print(f\"{BLUE}Running experiment: {name}{END}\")\n        print(f\"{BLUE}{'='*60}{END}\")\n        \n        predictions = []\n        token_counts = []\n        \n        for idx, example in enumerate(examples):\n            try:\n                print(f\"\\n{CYAN}Processing example {idx+1}/{len(examples)}{END}\")\n                logger.debug(f\"Input: {truncate_str(example['input'])}\")\n                \n                # Reset coordinator state for new episode\n                coordinator.reset()\n                \n                # Track tokens for this episode\n                episode_start_tokens = tracker.total_tokens\n                \n                # Extract agent outputs from dataset\n                context = example['context']\n                agent_outputs = [\n                    context['response_a'],\n                    context['response_b']\n                ]\n                \n                logger.debug(f\"Agent A ({context['model_a']}): {truncate_str(agent_outputs[0], 80)}\")\n                logger.debug(f\"Agent B ({context['model_b']}): {truncate_str(agent_outputs[1], 80)}\")\n                \n                # Coordinator processes both agent responses\n                state, coordinator_message = coordinator.step(agent_outputs)\n                \n                # Track tokens (agent outputs + coordinator message)\n                step_tokens = tracker.log_coordinator_step(agent_outputs, coordinator_message)\n                \n                # Make prediction based on coordinator's final state\n                # Simple heuristic: compare state activation with agent output lengths\n                prediction = predict_winner(state, agent_outputs, context)\n                predictions.append(prediction)\n                \n                # Record tokens for this episode\n                episode_tokens = tracker.total_tokens - episode_start_tokens\n                token_counts.append(episode_tokens)\n                \n                print(f\"{GREEN}Episode {idx+1} complete: prediction={prediction}, tokens={episode_tokens}{END}\")\n                \n            except Exception as e:\n                logger.error(f\"{RED}Error processing example {idx+1}: {e}{END}\")\n                # Add default prediction and token count to continue\n                predictions.append(\"tie\")\n                token_counts.append(0)\n        \n        print(f\"\\n{GREEN}Experiment {name} complete: {len(predictions)} predictions made{END}\")\n        return predictions, token_counts\n        \n    except Exception as e:\n        logger.error(f\"{RED}Error in run_experiment: {e}{END}\")\n        raise\n\ndef evaluate_performance(predictions: List[str], ground_truth: List[str]) -> Dict[str, float]:\n    \"\"\"\n    Evaluate task performance metrics.\n    \n    Args:\n        predictions: Predicted winners\n        ground_truth: Actual winners from dataset\n        \n    Returns:\n        Dictionary of performance metrics\n    \"\"\"\n    try:\n        print(f\"\\n{BLUE}Evaluating performance...{END}\")\n        \n        # Compute accuracy\n        accuracy = accuracy_score(ground_truth, predictions)\n        print(f\"  Accuracy: {accuracy:.4f}\")\n        \n        # Compute F1 scores\n        f1_macro = f1_score(ground_truth, predictions, average='macro', zero_division=0)\n        f1_weighted = f1_score(ground_truth, predictions, average='weighted', zero_division=0)\n        print(f\"  F1 (macro): {f1_macro:.4f}\")\n        print(f\"  F1 (weighted): {f1_weighted:.4f}\")\n        \n        metrics = {\n            \"accuracy\": float(accuracy),\n            \"f1_macro\": float(f1_macro), \n            \"f1_weighted\": float(f1_weighted)\n        }\n        \n        print(f\"{GREEN}Performance evaluation complete{END}\")\n        return metrics\n        \n    except Exception as e:\n        logger.error(f\"{RED}Error evaluating performance: {e}{END}\")\n        return {\n            \"accuracy\": 0.0,\n            \"f1_macro\": 0.0,\n            \"f1_weighted\": 0.0\n        }\n\ndef compute_statistical_significance(baseline_tokens: List[int], method_tokens: List[int]) -> Dict[str, Any]:\n    \"\"\"\n    Test if improvement is statistically significant.\n    \n    Args:\n        baseline_tokens: Token counts per episode for baseline\n        method_tokens: Token counts per episode for method\n        \n    Returns:\n        Dictionary of statistical test results\n    \"\"\"\n    try:\n        print(f\"\\n{BLUE}Computing statistical significance...{END}\")\n        \n        # Paired t-test (assumes normality)\n        t_stat, t_pval = ttest_rel(baseline_tokens, method_tokens)\n        t_significant = t_pval < 0.05\n        \n        print(f\"  Paired t-test: t={t_stat:.4f}, p={t_pval:.4f}, significant={t_significant}\")\n        \n        # Effect size (Cohen's d)\n        mean_diff = np.mean(baseline_tokens) - np.mean(method_tokens)\n        pooled_std = np.sqrt((np.var(baseline_tokens) + np.var(method_tokens)) / 2)\n        cohens_d = mean_diff / pooled_std if pooled_std > 0 else 0\n        \n        print(f\"  Effect size (Cohen's d): {cohens_d:.4f}\")\n        \n        results = {\n            \"t_statistic\": float(t_stat),\n            \"t_pvalue\": float(t_pval),\n            \"t_significant\": bool(t_significant),\n            \"cohens_d\": float(cohens_d),\n            \"alpha\": 0.05\n        }\n        \n        print(f\"{GREEN}Statistical tests complete{END}\")\n        return results\n        \n    except Exception as e:\n        logger.error(f\"{RED}Error computing statistical significance: {e}{END}\")\n        return {\n            \"t_statistic\": 0.0,\n            \"t_pvalue\": 1.0,\n            \"t_significant\": False,\n            \"cohens_d\": 0.0,\n            \"alpha\": 0.05\n        }\n\nprint(\"ðŸ”§ Experimental framework ready!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Experimental Framework\n\nNow we'll set up the experimental framework to run and compare both coordinators.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "class LowRankRecurrentCoordinator:\n    \"\"\"\n    Method: Low-rank recurrent coordinator with RIM-inspired sparse recurrence.\n\n    Key innovations:\n    1. Low-rank factorization: W = U @ V^T (reduces parameters)\n    2. Sparse recurrence: Only k modules active per step (reduces computation)\n    3. Compressed messaging: Messages encode only rank dimensions (reduces communication)\n    \"\"\"\n\n    def __init__(self, hidden_dim: int = 256, rank: int = 32, num_modules: int = 4):\n        \"\"\"\n        Initialize low-rank coordinator.\n\n        Args:\n            hidden_dim: Dimension of hidden state\n            rank: Low-rank factorization rank (k << hidden_dim)\n            num_modules: Number of RIM modules for sparse recurrence\n        \"\"\"\n        self.hidden_dim = hidden_dim\n        self.rank = rank\n        self.num_modules = num_modules\n\n        # Low-rank factorization: W = U @ V^T\n        self.U = np.random.randn(hidden_dim, rank) * 0.01\n        self.V = np.random.randn(hidden_dim, rank) * 0.01\n\n        # RIM sparse attention: only k modules active per step\n        self.active_k = max(1, num_modules // 2)\n\n        # Module-specific transformations (lightweight)\n        self.module_weights = [\n            np.random.randn(hidden_dim, rank) * 0.01\n            for _ in range(num_modules)\n        ]\n\n        self.state = np.zeros(hidden_dim)\n\n        compression_ratio = rank / hidden_dim\n        param_reduction = (2 * hidden_dim * rank) / (hidden_dim * hidden_dim)\n\n        logger.info(f\"{GREEN}LowRankRecurrentCoordinator initialized:{END}\")\n        logger.info(f\"  hidden_dim={hidden_dim}, rank={rank}, num_modules={num_modules}\")\n        logger.info(f\"  Compression ratio: {compression_ratio:.2%}\")\n        logger.info(f\"  Parameter reduction: {param_reduction:.2%} of full-rank\")\n        logger.info(f\"  Active modules per step: {self.active_k}/{num_modules}\")\n\n    def reset(self):\n        \"\"\"Reset coordinator state.\"\"\"\n        self.state = np.zeros(self.hidden_dim)\n        logger.debug(\"Coordinator state reset\")\n\n    def step(self, agent_outputs: List[str]) -> Tuple[np.ndarray, str]:\n        \"\"\"\n        Low-rank recurrent step with sparse module updates.\n\n        Args:\n            agent_outputs: List of agent response strings\n\n        Returns:\n            Tuple of (updated state, coordinator message)\n        \"\"\"\n        try:\n            logger.debug(f\"LowRankCoordinator.step with {len(agent_outputs)} agent outputs\")\n\n            # Encode agent outputs\n            features = self._encode_outputs(agent_outputs)\n            logger.debug(f\"  Encoded features shape: {features.shape}\")\n\n            # Select active modules (RIM sparse recurrence)\n            active_modules = self._select_active_modules(self.state, features)\n            logger.debug(f\"  Active modules: {active_modules}\")\n\n            # Low-rank recurrent update: s_{t+1} = U @ (V^T @ s_t) + module_updates\n            # This is equivalent to W @ s_t where W = U @ V^T, but much cheaper\n            state_proj = self.V.T @ self.state  # Project to rank-dimensional space\n            logger.debug(f\"  State projection shape: {state_proj.shape}\")\n\n            new_state = self.U @ state_proj  # Reconstruct in original space\n\n            # Apply sparse module updates (only active modules)\n            for module_idx in active_modules:\n                module_update = self.module_weights[module_idx] @ state_proj\n                new_state += module_update\n                logger.debug(f\"    Module {module_idx} update norm: {np.linalg.norm(module_update):.4f}\")\n\n            # Add features\n            new_state += features\n\n            self.state = new_state\n            logger.debug(f\"  State norm after update: {np.linalg.norm(self.state):.4f}\")\n\n            # Generate compressed coordinator message\n            # In low-rank, message only encodes rank dimensions (lower communication cost)\n            coordinator_message = self._generate_compressed_message(state_proj)\n            logger.debug(f\"  Coordinator message length: {len(coordinator_message)}\")\n\n            return self.state.copy(), coordinator_message\n\n        except Exception as e:\n            logger.error(f\"{RED}Error in LowRankCoordinator.step: {e}{END}\")\n            raise\n\n    def _encode_outputs(self, outputs: List[str]) -> np.ndarray:\n        \"\"\"Encode agent outputs into feature vector.\"\"\"\n        try:\n            # Simple encoding: token counts + basic text statistics\n            features = []\n            for output in outputs:\n                features.extend([\n                    len(output.split()),  # Word count\n                    len(output),  # Character count\n                    output.count('.'),  # Sentence markers\n                    output.count('?'),  # Question markers\n                ])\n\n            # Pad or truncate to hidden_dim\n            features_array = np.array(features[:self.hidden_dim])\n            if len(features_array) < self.hidden_dim:\n                padded = np.zeros(self.hidden_dim)\n                padded[:len(features_array)] = features_array\n                features_array = padded\n\n            # Normalize\n            features_array = features_array / (np.linalg.norm(features_array) + 1e-8)\n\n            logger.debug(f\"  Encoded {len(outputs)} outputs into {len(features_array)} features\")\n            return features_array\n\n        except Exception as e:\n            logger.error(f\"{RED}Error encoding outputs: {e}{END}\")\n            return np.zeros(self.hidden_dim)\n\n    def _select_active_modules(self, state: np.ndarray, features: np.ndarray) -> List[int]:\n        \"\"\"\n        Select top-k modules based on attention scores (RIM mechanism).\n\n        Args:\n            state: Current hidden state\n            features: Encoded input features\n\n        Returns:\n            List of active module indices\n        \"\"\"\n        try:\n            # Compute attention scores for each module\n            scores = []\n            state_proj = self.V.T @ state  # Project to rank space\n\n            for module_idx, module_w in enumerate(self.module_weights):\n                # Score = similarity between module projection and features\n                module_proj = module_w.T @ features\n                score = np.dot(module_proj[:self.rank], state_proj)\n                scores.append((score, module_idx))\n\n            # Return top-k active modules\n            scores.sort(reverse=True)\n            active = [idx for _, idx in scores[:self.active_k]]\n\n            logger.debug(f\"  Module scores: {[(idx, f'{score:.4f}') for score, idx in scores]}\")\n            return active\n\n        except Exception as e:\n            logger.error(f\"{RED}Error selecting active modules: {e}{END}\")\n            # Fallback: return first k modules\n            return list(range(self.active_k))\n\n    def _generate_compressed_message(self, state_proj: np.ndarray) -> str:\n        \"\"\"\n        Generate compressed coordinator message from projected state.\n\n        In low-rank, message only encodes rank dimensions (much smaller than full state).\n        This is the key to reduced communication cost.\n        \"\"\"\n        # Simulate message as string representation of compressed state\n        message_parts = []\n        for i in range(len(state_proj)):\n            val = state_proj[i]\n            if abs(val) > 0.1:  # Only include significant values\n                message_parts.append(f\"r{i}:{val:.2f}\")\n\n        message = \" \".join(message_parts)\n        logger.debug(f\"  Generated compressed message with {len(message_parts)} components (vs {self.hidden_dim} in full-rank)\")\n        return message\n\n# Test the low-rank coordinator\nmethod_coordinator = LowRankRecurrentCoordinator(hidden_dim=256, rank=32, num_modules=4)\nstate, message = method_coordinator.step(sample_outputs)\n\nprint(f\"ðŸ§  Method coordinator state shape: {state.shape}\")\nprint(f\"ðŸ’¬ Coordinator message preview: {message[:100]}...\")\n\n# Calculate parameter efficiency\nbaseline_params = 256 * 256\nmethod_params = 2 * 256 * 32 + 4 * 256 * 32  # U, V matrices + module weights\nreduction = (baseline_params - method_params) / baseline_params * 100\n\nprint(f\"ðŸ“Š Baseline parameters: {baseline_params:,}\")\nprint(f\"ðŸ“Š Method parameters: {method_params:,}\")\nprint(f\"ðŸ“‰ Parameter reduction: {reduction:.1f}%\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Method: Low-Rank Recurrent Coordinator\n\nThe proposed method uses low-rank factorization (W = U @ V^T) with RIM-inspired sparse recurrence to reduce parameter count and communication cost.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "class FullRankCoordinator:\n    \"\"\"Baseline: Full-rank recurrent coordinator for multi-agent coordination.\"\"\"\n\n    def __init__(self, hidden_dim: int = 256):\n        \"\"\"\n        Initialize full-rank coordinator.\n\n        Args:\n            hidden_dim: Dimension of hidden state\n        \"\"\"\n        self.hidden_dim = hidden_dim\n        self.W = np.random.randn(hidden_dim, hidden_dim) * 0.01\n        self.state = np.zeros(hidden_dim)\n\n        logger.info(f\"{GREEN}FullRankCoordinator initialized: hidden_dim={hidden_dim}{END}\")\n        logger.info(f\"  Weight matrix shape: {self.W.shape}\")\n        logger.info(f\"  Total parameters: {self.W.size}\")\n\n    def reset(self):\n        \"\"\"Reset coordinator state.\"\"\"\n        self.state = np.zeros(self.hidden_dim)\n        logger.debug(\"Coordinator state reset\")\n\n    def step(self, agent_outputs: List[str]) -> Tuple[np.ndarray, str]:\n        \"\"\"\n        Recurrent step: process agent outputs and update state.\n\n        Args:\n            agent_outputs: List of agent response strings\n\n        Returns:\n            Tuple of (updated state, coordinator message)\n        \"\"\"\n        try:\n            logger.debug(f\"FullRankCoordinator.step with {len(agent_outputs)} agent outputs\")\n\n            # Encode agent outputs into feature vector\n            features = self._encode_outputs(agent_outputs)\n            logger.debug(f\"  Encoded features shape: {features.shape}\")\n\n            # Full-rank recurrent update: s_{t+1} = W @ s_t + features\n            self.state = self.W @ self.state + features\n            logger.debug(f\"  State norm after update: {np.linalg.norm(self.state):.4f}\")\n\n            # Generate coordinator message (simulates communication)\n            # In full-rank, message includes all state dimensions\n            coordinator_message = self._generate_message(self.state)\n            logger.debug(f\"  Coordinator message length: {len(coordinator_message)}\")\n\n            return self.state.copy(), coordinator_message\n\n        except Exception as e:\n            logger.error(f\"{RED}Error in FullRankCoordinator.step: {e}{END}\")\n            raise\n\n    def _encode_outputs(self, outputs: List[str]) -> np.ndarray:\n        \"\"\"Encode agent outputs into feature vector.\"\"\"\n        try:\n            # Simple encoding: token counts + basic text statistics\n            features = []\n            for output in outputs:\n                features.extend([\n                    len(output.split()),  # Word count\n                    len(output),  # Character count\n                    output.count('.'),  # Sentence markers\n                    output.count('?'),  # Question markers\n                ])\n\n            # Pad or truncate to hidden_dim\n            features_array = np.array(features[:self.hidden_dim])\n            if len(features_array) < self.hidden_dim:\n                padded = np.zeros(self.hidden_dim)\n                padded[:len(features_array)] = features_array\n                features_array = padded\n\n            # Normalize\n            features_array = features_array / (np.linalg.norm(features_array) + 1e-8)\n\n            logger.debug(f\"  Encoded {len(outputs)} outputs into {len(features_array)} features\")\n            return features_array\n\n        except Exception as e:\n            logger.error(f\"{RED}Error encoding outputs: {e}{END}\")\n            return np.zeros(self.hidden_dim)\n\n    def _generate_message(self, state: np.ndarray) -> str:\n        \"\"\"\n        Generate coordinator message from state.\n\n        In full-rank, message encodes entire state (high communication cost).\n        \"\"\"\n        # Simulate message as string representation of state\n        # Message length proportional to number of dimensions\n        message_parts = []\n        for i in range(0, len(state), 10):\n            # Sample every 10th dimension to create message\n            val = state[i]\n            if abs(val) > 0.1:  # Only include significant values\n                message_parts.append(f\"dim{i}:{val:.2f}\")\n\n        message = \" \".join(message_parts)\n        logger.debug(f\"  Generated message with {len(message_parts)} components\")\n        return message\n\n# Test the full-rank coordinator\nbaseline_coordinator = FullRankCoordinator(hidden_dim=256)\nsample_outputs = [\"This is response A\", \"This is response B\"]\nstate, message = baseline_coordinator.step(sample_outputs)\n\nprint(f\"ðŸ§  Baseline coordinator state shape: {state.shape}\")\nprint(f\"ðŸ’¬ Coordinator message preview: {message[:100]}...\")\nprint(f\"ðŸ“Š Parameters: {baseline_coordinator.W.size:,}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Baseline: Full-Rank Recurrent Coordinator\n\nThe baseline coordinator uses a full-rank recurrent matrix (256Ã—256 parameters) to process agent outputs.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "class TokenTracker:\n    \"\"\"Track token usage for multi-agent coordination.\"\"\"\n\n    def __init__(self, model: str = \"gpt-4\"):\n        \"\"\"Initialize token tracker with tiktoken encoder.\"\"\"\n        try:\n            self.encoding = tiktoken.encoding_for_model(model)\n            logger.info(f\"{GREEN}TokenTracker initialized with model: {model}{END}\")\n        except Exception as e:\n            logger.warning(f\"{YELLOW}Could not load model-specific encoding, using cl100k_base: {e}{END}\")\n            self.encoding = tiktoken.get_encoding(\"cl100k_base\")\n\n        self.total_tokens = 0\n        self.episode_tokens = []\n        self.call_count = 0\n\n    def count_tokens(self, text: str) -> int:\n        \"\"\"Count tokens in text.\"\"\"\n        try:\n            tokens = len(self.encoding.encode(text))\n            logger.debug(f\"Counted {tokens} tokens in text: {truncate_str(text, 50)}\")\n            return tokens\n        except Exception as e:\n            logger.error(f\"{RED}Error counting tokens: {e}{END}\")\n            # Fallback: approximate as words * 1.3\n            approx = int(len(text.split()) * 1.3)\n            logger.warning(f\"{YELLOW}Using approximate token count: {approx}{END}\")\n            return approx\n\n    def log_coordinator_step(self, agent_outputs: List[str], coordinator_message: str = \"\"):\n        \"\"\"Log tokens for a coordinator step.\"\"\"\n        try:\n            step_tokens = 0\n\n            # Count tokens in agent outputs (what coordinator processes)\n            for idx, output in enumerate(agent_outputs):\n                output_tokens = self.count_tokens(output)\n                step_tokens += output_tokens\n                logger.debug(f\"  Agent {idx} output: {output_tokens} tokens\")\n\n            # Count tokens in coordinator's internal message (communication cost)\n            if coordinator_message:\n                coord_tokens = self.count_tokens(coordinator_message)\n                step_tokens += coord_tokens\n                logger.debug(f\"  Coordinator message: {coord_tokens} tokens\")\n\n            self.total_tokens += step_tokens\n            self.episode_tokens.append(step_tokens)\n            self.call_count += 1\n\n            logger.info(f\"{CYAN}Step {self.call_count}: {step_tokens} tokens (total: {self.total_tokens}){END}\")\n            return step_tokens\n\n        except Exception as e:\n            logger.error(f\"{RED}Error logging coordinator step: {e}{END}\")\n            return 0\n\n    def get_stats(self) -> Dict[str, float]:\n        \"\"\"Get aggregated token statistics.\"\"\"\n        stats = {\n            \"total_tokens\": self.total_tokens,\n            \"num_episodes\": len(self.episode_tokens),\n            \"mean_tokens_per_episode\": np.mean(self.episode_tokens) if self.episode_tokens else 0,\n            \"std_tokens_per_episode\": np.std(self.episode_tokens) if self.episode_tokens else 0,\n            \"call_count\": self.call_count\n        }\n        logger.debug(f\"Token stats: {stats}\")\n        return stats\n\n# Test the token tracker\ntracker = TokenTracker()\ntest_text = \"This is a sample text for token counting.\"\ntokens = tracker.count_tokens(test_text)\nprint(f\"ðŸ”¢ Token count for '{test_text}': {tokens} tokens\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Token Tracking System\n\nThe TokenTracker class monitors communication costs between agents and the coordinator.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Define data structures\n@dataclass\nclass ExampleResult:\n    \"\"\"Single example result.\"\"\"\n    input: str\n    output: str\n    context: Dict[str, Any]\n    dataset: str\n    split: str\n    predict_baseline: str\n    predict_method: str\n    method: str\n\n@dataclass\nclass ExperimentResult:\n    \"\"\"Schema matching experiment output format.\"\"\"\n    examples: List[Dict[str, Any]]\n\n# Sample dataset (inlined from JSON files to make notebook self-contained)\nSAMPLE_DATASET = {\n    \"examples\": [\n        {\n            \"input\": \"What is the difference between OpenCL and CUDA?\",\n            \"output\": \"Winner: model_b\",\n            \"context\": {\n                \"model_a\": \"chatglm-6b\",\n                \"model_b\": \"koala-13b\",\n                \"winner\": \"model_b\",\n                \"judge\": \"arena_user_973\",\n                \"language\": \"English\",\n                \"turn\": 1,\n                \"response_a\": \"OpenCL and CUDA are two different programming models that are used for parallel computing.OpenCL is a general-purposeå¹¶è¡Œç¼–ç¨‹æŽ¥å£ that allows developers to write parallel code that can run on any platform that supportsCL, which includes most modern operating systems and computer systems, including Windows, Linux, and macOS. It provides a lower-level, more flexible API that is more suitable for building large-scale distributed computing systems.CUDA is a specific implementation ofOpenCL that is designed for performance and scalability in devices with multiple GPU(s). It was developed by Nvidia and is widely used for scientific computing, machine learning, andå›¾å½¢å›¾åƒå¤„ç†. The CUDA API provides a high-level, more efficient way to write parallel code that can run on top of a GPU, while still maintaining the ability to write code that can be easily adapted for other parallel computing platforms.\",\n                \"response_b\": \"OpenCL and CUDA are both programming languages for parallel computing on GPUs, but they differ in several key ways:\\\\n\\\\n1.   Architecture: OpenCL is a general-purpose parallel computing language, while CUDA is designed specifically for GPU computing. OpenCL can run on various types of processors, including CPUs, GPUs, and FPGAs, whereas CUDA is only compatible with NVIDIA GPUs.\\\\n2.   Language: OpenCL is a C++ language, while CUDA is a C++ language with additional features for GPU computing. CUDA provides additional libraries and tools for handling graphics and other tasks unique to GPUs.\\\\n3.   Driver support: OpenCL has a wider range of device support, with support for not just NVIDIA GPUs but also other manufacturers like AMD, Intel, and ARM. CUDA is only available on NVIDIA GPUs, and requires the CUDA Toolkit to be installed on the host machine.\\\\n4.   Memory management: OpenCL provides a unified memory model, where all the data is stored in global memory, and the kernel can access any part of it. CUDA, on the other hand, uses a hierarchical memory architecture, where data is divided into host, device, and shared memory.\\\\n5.   Performance: OpenCL and CUDA have different strengths and weaknesses in terms of performance. OpenCL is generally faster for numerical computations, while CUDA is faster for graphics and other tasks that require fast memory access. CUDA also has better support for 64-bit floating-point operations, which are essential for some scientific applications.\\\\n\\\\nIn summary, OpenCL and CUDA are both programming languages for parallel computing on GPUs, but they differ in terms of architecture, language, driver support, memory management, and performance. OpenCL is a general-purpose language that can run on various types of processors, while CUDA is specific to NVIDIA GPUs and provides additional libraries and tools for handling graphics and other tasks unique to GPUs.\"\n            },\n            \"dataset\": \"lmsys/chatbot_arena_conversations\",\n            \"split\": \"train\"\n        },\n        {\n            \"input\": \"Why did my parent not invite me to their wedding?\",\n            \"output\": \"Winner: tie\",\n            \"context\": {\n                \"model_a\": \"oasst-pythia-12b\",\n                \"model_b\": \"alpaca-13b\",\n                \"winner\": \"tie\",\n                \"judge\": \"arena_user_973\",\n                \"language\": \"English\",\n                \"turn\": 1,\n                \"response_a\": \"It is possible that your parent did not invite you to their wedding for a variety of reasons. It could be that they did not want to burden you with the planning or expense of the event, or they may not have had the time or resources to include you. Additionally, it could be that they did not feel comfortable having you attend due to your age or relationship with them. It is important to remember that your parent may have had their own reasons for not inviting you, and it is not your place to judge their choices. If you feel neglected or upset about not being invited, it is best to talk to them about it and express your feelings in a non-accusatory way.\",\n                \"response_b\": \"It is likely that they wanted to keep the guest list small and intimate. Maybe they felt that inviting you would make the event too crowded, or that they wanted to keep the event reserved for close friends and family. It could be that they wanted to avoid any potential drama or conflict that could arise from having too many people at the event. Whatever the reason, it's important to remember that they made this decision out of love and respect for you, and that their decision doesn't define your relationship.\"\n            },\n            \"dataset\": \"lmsys/chatbot_arena_conversations\",\n            \"split\": \"train\"\n        },\n        {\n            \"input\": \"Fuji vs. Nikon, which is better?\",\n            \"output\": \"Winner: model_b\",\n            \"context\": {\n                \"model_a\": \"koala-13b\",\n                \"model_b\": \"oasst-pythia-12b\",\n                \"winner\": \"model_b\",\n                \"judge\": \"arena_user_973\",\n                \"language\": \"English\",\n                \"turn\": 1,\n                \"response_a\": \"Both Fuji and Nikon are popular camera brands that offer a wide range of cameras for different types of photography. It really depends on your specific needs and preferences as to which brand is \\\\\\\"better\\\\\\\" for you.\\\\n\\\\nFujifilm is known for its high image quality, especially in the areas of color accuracy and dynamic range. Many photographers also appreciate the company's focus on ergonomics and the overall user experience of its cameras. Additionally, Fujifilm has a loyal following among enthusiasts and professional photographers, thanks to its commitment to film photography and its high-end mirrorless cameras.\\\\n\\\\nNikon, on the other hand, is known for its advanced autofocus system and image stabilization technology, as well as its high-end cameras and lenses. Nikon also has a wide selection of cameras and lenses to choose from, including both DSLR and mirrorless options.\\\\n\\\\nUltimately, it's difficult to say which brand is \\\\\\\"better\\\\\\\" without knowing more about your specific needs and preferences. It might be helpful to research both brands further and try out a few different models before making a decision.\",\n                \"response_b\": \"This is a subjective question and the answer depends on the individual preferences and needs. Both Fujifilm and Nikon are well-known for their high-quality cameras, and the choice between the two ultimately depends on the user's personal preferences and needs.\\\\n\\\\nSome factors to consider when deciding between a Fuji and a Nikon camera include:\\\\n\\\\n1. Image quality: Fuji cameras are known for their high-quality images, with a distinctive film-like quality. Nikon cameras are also notable for their image quality, but they may not offer the same level of sharpness and color accuracy as Fuji cameras.\\\\n\\\\n2. Focusing: Fuji cameras are known for their fast and precise autofocus, while Nikon cameras tend to have a slower and more manual focus system.\\\\n\\\\n3. Image size: Fuji cameras are known for their wide range of photo sizes, from small compacts to large-format cameras. Nikon cameras are also capable of producing high-quality images, but they may not be as versatile as Fuji cameras.\\\\n\\\\n4. User interface: Fuji cameras have a user-friendly interface, with a simplified design that is easy to navigate. Nikon cameras may have a more complex interface, but they also offer a wealth of features and customization options.\\\\n\\\\nUltimately, the best camera for you will depend on your specific needs and preferences. If you're looking for a high-quality camera that offers a unique film-like experience, a Fuji camera may be the right choice for you. If you're looking for a camera that is easy to use and offers a wide range of photo sizes, a Nikon camera may be the best choice.\"\n            },\n            \"dataset\": \"lmsys/chatbot_arena_conversations\",\n            \"split\": \"train\"\n        }\n    ]\n}\n\nprint(f\"ðŸ“ Dataset loaded: {len(SAMPLE_DATASET['examples'])} examples\")\nprint(f\"ðŸŽ¯ Example structure: {list(SAMPLE_DATASET['examples'][0].keys())}\")\nprint(f\"ðŸ” First question: {SAMPLE_DATASET['examples'][0]['input']}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Data Schema and Sample Dataset\n\nWe use data from the lmsys/chatbot_arena_conversations dataset with multi-agent interactions. Each example contains agent responses that need to be coordinated.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Import required libraries\nimport json\nimport logging\nimport sys\nfrom pathlib import Path\nfrom typing import Dict, List, Tuple, Any\nfrom dataclasses import dataclass, asdict\n\nimport numpy as np\nimport tiktoken\nfrom scipy.linalg import svd\nfrom sklearn.metrics import accuracy_score, f1_score\nfrom scipy.stats import ttest_rel\n\n# Configure logging for interactive use\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s | %(levelname)-7s | %(funcName)-20s | %(message)s'\n)\nlogger = logging.getLogger(__name__)\n\n# Color codes for enhanced output\nBLUE, GREEN, YELLOW, CYAN, RED, END = \"\\033[94m\", \"\\033[92m\", \"\\033[93m\", \"\\033[96m\", \"\\033[91m\", \"\\033[0m\"\n\ndef truncate_str(text: str, max_len: int = 100) -> str:\n    \"\"\"Truncate long strings for logging.\"\"\"\n    if len(text) <= max_len:\n        return text\n    return text[:max_len] + f\"... ({len(text)} chars total)\"\n\nprint(\"âœ… Libraries imported successfully!\")\nprint(\"ðŸ“Š Ready to analyze low-rank recurrent coordinators\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Empirical Evaluation of Low-Rank Recurrent Coordinator on Multi-LLM Communication Efficiency\n\nThis notebook demonstrates a low-rank recurrent coordinator for multi-LLM agent communication efficiency. The experiment compares a baseline full-rank coordinator against a low-rank coordinator with RIM-inspired sparse recurrence.\n\n## Key Components\n1. **Baseline**: Full-rank recurrent coordinator (256Ã—256 parameters)\n2. **Method**: Low-rank recurrent coordinator (rank=32, 4 RIM modules, 25% parameters)\n3. **Evaluation**: Token efficiency vs task performance on multi-agent interactions\n\n## Hypothesis\nLow-rank coordinator reduces token usage by >15% while maintaining task performance.",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}